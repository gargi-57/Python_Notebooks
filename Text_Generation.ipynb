{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNx7VpEi35M4pvC2MuapnbB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gargi-57/Python_Notebooks/blob/main/Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CPpVer44dB2M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available and being used\")\n",
        "\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"GPU is not available, using CPU instead\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA8SsRLndJq0",
        "outputId": "a61d787d-6493-41bf-9bff-417ff8266cde"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and being used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"/content/gutenberg.txt\"\n",
        "text = open(filename,'r',encoding='utf-8').read()\n",
        "text = text.lower()\n",
        "text = re.sub(r'\\ufeff','',text)"
      ],
      "metadata": {
        "id": "wgtS0MrldPae"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mappings for unique characters and creating unique indexes for characters\n",
        "chars = sorted(list(set(text)))\n",
        "chars_to_int = dict((c,i) for i,c in enumerate(chars))"
      ],
      "metadata": {
        "id": "K04O7-GyfO83"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vocabulary and Data\n",
        "n_chars = len(text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters:\",n_chars)\n",
        "print(\"Total Unique Characters i.e. Vocabulary:\",n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QahAiFUqgHgy",
        "outputId": "c2954e26-233b-4ab7-cdcd-010ff282127d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters: 412715\n",
            "Total Unique Characters i.e. Vocabulary: 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_to_int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww3XfjSWgykC",
        "outputId": "a450acf6-17fb-4fbd-f2b7-27df84cea677"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '#': 3,\n",
              " '$': 4,\n",
              " '%': 5,\n",
              " '&': 6,\n",
              " '(': 7,\n",
              " ')': 8,\n",
              " '*': 9,\n",
              " ',': 10,\n",
              " '-': 11,\n",
              " '.': 12,\n",
              " '/': 13,\n",
              " '0': 14,\n",
              " '1': 15,\n",
              " '2': 16,\n",
              " '3': 17,\n",
              " '4': 18,\n",
              " '5': 19,\n",
              " '6': 20,\n",
              " '7': 21,\n",
              " '8': 22,\n",
              " '9': 23,\n",
              " ':': 24,\n",
              " ';': 25,\n",
              " '=': 26,\n",
              " '?': 27,\n",
              " '[': 28,\n",
              " ']': 29,\n",
              " '_': 30,\n",
              " 'a': 31,\n",
              " 'b': 32,\n",
              " 'c': 33,\n",
              " 'd': 34,\n",
              " 'e': 35,\n",
              " 'f': 36,\n",
              " 'g': 37,\n",
              " 'h': 38,\n",
              " 'i': 39,\n",
              " 'j': 40,\n",
              " 'k': 41,\n",
              " 'l': 42,\n",
              " 'm': 43,\n",
              " 'n': 44,\n",
              " 'o': 45,\n",
              " 'p': 46,\n",
              " 'q': 47,\n",
              " 'r': 48,\n",
              " 's': 49,\n",
              " 't': 50,\n",
              " 'u': 51,\n",
              " 'v': 52,\n",
              " 'w': 53,\n",
              " 'x': 54,\n",
              " 'y': 55,\n",
              " 'z': 56,\n",
              " '£': 57,\n",
              " '°': 58,\n",
              " 'à': 59,\n",
              " 'â': 60,\n",
              " 'æ': 61,\n",
              " 'ç': 62,\n",
              " 'è': 63,\n",
              " 'é': 64,\n",
              " 'ê': 65,\n",
              " 'ô': 66,\n",
              " 'ü': 67,\n",
              " '—': 68,\n",
              " '‘': 69,\n",
              " '’': 70,\n",
              " '“': 71,\n",
              " '”': 72,\n",
              " '•': 73,\n",
              " '™': 74}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_i = text[0:10]\n",
        "print(seq_i)\n",
        "print(\"____________________________________\")\n",
        "seq_o = text[10]\n",
        "print(seq_o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OMDs_WJg_DK",
        "outputId": "17b2cdde-6ffb-4b4c-b369-ed6a5032569d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the projec\n",
            "____________________________________\n",
            "t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Preparation\n",
        "\n",
        "seq_length = 100\n",
        "x =[]\n",
        "y= []\n",
        "\n",
        "for i in range(0,n_chars - seq_length,1):\n",
        "  seq_in= text[i:i+seq_length]\n",
        "  seq_out = text[i+seq_length]\n",
        "  x.append([chars_to_int[char] for char in seq_in])\n",
        "  y.append(chars_to_int[seq_out])\n",
        "patterns = len(x)\n",
        "print(\"Total Patterns for Sentence Generation:\",patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbRp5Zw2hiLw",
        "outputId": "fc45cbab-8f49-462e-b8d6-6fd30d169978"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns for Sentence Generation: 412615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape data for LSTM\n",
        "data_X = torch.tensor(x,dtype=torch.float32).reshape(patterns,seq_length,1)\n",
        "data_X = data_X/float(n_vocab)\n",
        "data_y = torch.tensor(y)"
      ],
      "metadata": {
        "id": "S05YAfKQio40"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "units = 256\n",
        "layers = 1\n",
        "#Define Model\n",
        "class Gen_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTM(input_size= 1,hidden_size = units,num_layers=layers,batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.linear = nn.Linear(units,n_vocab)\n",
        "  def forward(self,x):\n",
        "    x,_ = self.lstm(x)\n",
        "    x = x[:,-1,:]\n",
        "    x = self.linear(self.dropout(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "QUhyRUcyj5A8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size =120\n",
        "model = Gen_Model()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "6AKsiE8tloGt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "loader = data.DataLoader(data.TensorDataset(data_X,data_y),shuffle = True,batch_size = batch_size)"
      ],
      "metadata": {
        "id": "nApb3M9CmJFP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = None\n",
        "best_loss = np.inf\n",
        "for epoch in range(n_epochs):\n",
        "  model.train()\n",
        "  for X_batch,y_batch in loader:\n",
        "    y_pred = model(X_batch.to(device))\n",
        "    loss= loss_fn(y_pred,y_batch.to(device))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  #Validation\n",
        "  model.eval()\n",
        "  loss = 0\n",
        "  with torch.no_grad():\n",
        "    for X_batch,y_batch in loader:\n",
        "      y_pred = model(X_batch.to(device))\n",
        "      loss += loss_fn(y_pred,y_batch.to(device))\n",
        "\n",
        "    if loss < best_loss:\n",
        "      best_loss = loss\n",
        "      best_model = model.state_dict()\n",
        "      print(\"Epoch %d: Cross entropy: %.4f\" % (epoch,loss))\n",
        "torch.save([best_model, chars_to_int],\"single-char_prediction.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caJ160FQm5UU",
        "outputId": "0da3c906-3589-4a2c-f502-4f1a4e7c91ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Cross entropy: 1137911.3750\n",
            "Epoch 1: Cross entropy: 1102504.1250\n",
            "Epoch 2: Cross entropy: 1079620.1250\n",
            "Epoch 3: Cross entropy: 1049106.6250\n",
            "Epoch 4: Cross entropy: 1024073.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "start = np.random.randint(0,len(text)-seq_length)\n",
        "prompt = text[start:start+seq_length]\n",
        "pattern = [chars_to_int[c] for c in prompt]"
      ],
      "metadata": {
        "id": "D1djOY1tqgAA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model,chars_to_init = torch.load(\"single-char_prediction.pth\")\n",
        "n_vocab = len(chars_to_int)\n",
        "int_to_char = dict((i,c) for c, i in chars_to_int.items())"
      ],
      "metadata": {
        "id": "52JIiXk5pihd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mPGNRTkrf15",
        "outputId": "967841a6-f25f-49e1-be59-93a1bbd22eb0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prompt:  \"%s\"' % prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_trZ6lXcrr_E",
        "outputId": "f4a996af-6c4d-43b7-b0b4-2f3052dfdba7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:  \"dy and practical work. they looked\n",
            "a fine body of men, and have been greatly appreciated by the miss\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for i in range(1000):\n",
        "    # create a input\n",
        "    x = np.reshape(pattern,(1,len(pattern),1)) / float(n_vocab)\n",
        "    x = torch.tensor(x, dtype=torch.float32)\n",
        "    #generate logits as output\n",
        "    prediction = model(x.to(device))\n",
        "    #convert logits into character\n",
        "    index = int(prediction.argmax())\n",
        "    result = int_to_char[index]\n",
        "    print(result,end =\"\")\n",
        "    #append the new character into the prompt for the next iteration\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww-euqcgsDhe",
        "outputId": "64b6c511-5751-40a3-890f-10f0cbba4e33"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " of the cornent of the cornent oo the cornent of the cornent oo the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo the cornent of the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo the cornent of the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo the cornent of the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo the cornent of the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo the cornent of the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo the cornent of the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo the cornent of the coine tf tee the cart of the cornent oo the cornent of the cornent oo the cornent of the cornent oo"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCxHJbUl0XV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}